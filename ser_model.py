# -*- coding: utf-8 -*-
"""SER_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q4GAdhbQ_IGZm8bdYt9fm1pmtO_L4Wxz
"""

from google.colab import drive
drive.mount('/content/drive')

# Change this path to where your ZIP is stored in Drive
zip_path = "/content/drive/MyDrive/emotion-recognition-using-speech-master.zip"

# Unzip into /content
!unzip -q "$zip_path" -d /content/

# Commented out IPython magic to ensure Python compatibility.
# set repo dir (change if different)
REPO_DIR = "/content/emotion-recognition-using-speech-master"
# %cd "$REPO_DIR"
!ls -la

!pip install -q numpy==1.26.4 pandas==1.3.5 librosa==0.8.1 soundfile==0.10.3.post1 scikit-learn==1.3.2 tensorflow==2.16.1 matplotlib seaborn

!pip install librosa==0.8.1

!pip install soundfile==0.10.3.post1

!pip install scikit-learn==1.0.2

!pip install pandas==1.3.5

pip install numpy==1.26.4 pandas==1.3.5 librosa==0.8.1 soundfile==0.10.3.post1 scikit-learn==1.3.2

pip install --upgrade librosa==0.10.1

import os
import librosa
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM

DATA_PATH = "/content/emotion-recognition-using-speech-master/data/training"

import os
print("Files in DATA_PATH:", os.listdir(DATA_PATH))

def extract_features(file_path, max_pad_len=174):
    try:
        audio, sr = librosa.load(file_path, sr=22050)  # load audio
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)

        # Pad/truncate to fixed length
        if mfccs.shape[1] < max_pad_len:
            pad_width = max_pad_len - mfccs.shape[1]
            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')
        else:
            mfccs = mfccs[:, :max_pad_len]

        return mfccs
    except Exception as e:
        print(f"âŒ Error processing {file_path}: {e}")
        return None

labels = []
features = []

for root, dirs, files in os.walk(DATA_PATH):
    for file in files:
        if file.endswith(".wav"):
            file_path = os.path.join(root, file)

            # Extract features
            data = extract_features(file_path)

            if data is not None:
                features.append(data)
                # Label = Actor_xx
                labels.append(os.path.basename(root))

X = np.array(features)
y = np.array(labels)

print("âœ… Features shape:", X.shape)
print("âœ… Labels shape:", y.shape)

print("Features shape:", X.shape)
print("Labels shape:", y.shape)
print("Unique labels:", np.unique(y))

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# --- Save with SER-specific names ---
X_ser_train, X_ser_test = X_train, X_test
y_ser_train, y_ser_test = y_train, y_test

from tensorflow.keras.layers import Input, LSTM, Dropout, Dense
from tensorflow.keras.models import Sequential

model = Sequential([
    Input(shape=(40, 174)),   # 40 timesteps, 174 features
    LSTM(128, return_sequences=True),
    Dropout(0.3),
    LSTM(64),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(len(np.unique(y_encoded)), activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))

# 2. Evaluate on test set
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"âœ… Test Accuracy: {test_acc:.4f}")
print(f"âœ… Test Loss: {test_loss:.4f}")

import matplotlib.pyplot as plt

# Graph 1: Training & Validation Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Training vs Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# Graph 2: Training & Validation Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Training vs Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predictions
y_pred = model.predict(X_test)
y_pred_classes = y_pred.argmax(axis=1)

# If y_test is already integer labels
y_true = y_test

# Confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)

disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix")
plt.show()

# Training accuracy (last epoch)
train_acc = history.history['accuracy'][-1]


# Validation accuracy (last epoch)
val_acc = history.history['val_accuracy'][-1]

print(f"Final Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)")
print(f"Final Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)")
print(f"Final Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")

import matplotlib.pyplot as plt

# Final accuracies
train_acc = 0.9683   # replace with your actual final training accuracy
val_acc   = 0.8290   # replace with your actual final validation accuracy
test_acc  = 0.8290   # replace with your actual final test accuracy

# Labels and values
labels = ['Training Accuracy', 'Validation Accuracy', 'Test Accuracy']
values = [train_acc, val_acc, test_acc]

# Plot bar chart
plt.figure(figsize=(6, 4))
bars = plt.bar(labels, values, color=['skyblue', 'lightgreen', 'salmon'])

# Add value labels on top of bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f"{yval*100:.2f}%",
             ha='center', va='bottom', fontsize=10, fontweight='bold')

plt.title("Final Model Accuracies")
plt.ylabel("Accuracy")
plt.ylim(0, 1.1)  # show up to 110% for clarity
plt.show()

# Save the entire model
model.save("speech_emotion_model.h5")
print("âœ… Model saved as speech_emotion_model.h5")

from tensorflow.keras.models import load_model

# Load the saved model
loaded_model = load_model("speech_emotion_model.h5")
print("âœ… Model loaded successfully")

# Save entire model (architecture + weights + optimizer state)
model.save("/content/drive/MyDrive/Multimodal_Emotion_Models/speech_emotion_model.keras", save_format="keras")
print("âœ… Model saved to Google Drive as speech_emotion_model.h5")

from tensorflow.keras.models import load_model

# Load model from Drive
loaded_model = load_model("/content/drive/MyDrive/Multimodal_Emotion_Models/speech_emotion_model.keras")
print("âœ… Model loaded from Google Drive")

import tensorflow as tf

# Load the full model back
ser_model = tf.keras.models.load_model(
    "/content/drive/MyDrive/Multimodal_Emotion_Models/speech_emotion_model.keras"
)

print("âœ… SER model loaded successfully!")
ser_model.summary()

import tensorflow as tf
from tensorflow.keras import layers, models

# Load your existing model
loaded_model = tf.keras.models.load_model(
    "/content/drive/MyDrive/Multimodal_Emotion_Models/speech_emotion_model.keras"
)

# âœ… Check original input shape
print("Original input shape:", loaded_model.input_shape)

# âœ… Rebuild with CPU-compatible LSTMs (fix input shape)
new_model = models.Sequential([
    layers.Input(shape=(40, 174)),   # <-- fix here (timesteps=40, features=174)
    layers.LSTM(128, return_sequences=True,
                activation="tanh",
                recurrent_activation="sigmoid",
                implementation=2),
    layers.Dropout(0.3),
    layers.LSTM(64,
                activation="tanh",
                recurrent_activation="sigmoid",
                implementation=2),
    layers.Dropout(0.3),
    layers.Dense(64, activation="relu"),
    layers.Dense(26, activation="softmax")
])

# âœ… Transfer weights (layer by layer)
for i in range(len(new_model.layers)):
    try:
        new_model.layers[i].set_weights(loaded_model.layers[i].get_weights())
        print(f"Transferred weights for layer {i}: {loaded_model.layers[i].name}")
    except Exception as e:
        print(f"âš ï¸ Skipped layer {i}: {e}")

# Compile new model
new_model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# âœ… Save as SavedModel (for TFLite conversion)
new_model.export("ser_cpu_saved_model")

print("âœ… Rebuilt SER model with CPU LSTMs and exported for TFLite conversion!")

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, LSTM, Dropout, Dense

# Load original model
original_model = keras.models.load_model(
    "/content/drive/MyDrive/Multimodal_Emotion_Models/speech_emotion_model.keras",
    compile=False
)

print("Original input shape:", original_model.input_shape)

# --- Rebuild CPU-compatible model ---
inputs = Input(shape=(40, 174))  # adjust if needed

x = LSTM(128, return_sequences=True, activation="tanh", recurrent_activation="sigmoid")(inputs)
x = Dropout(0.3)(x)
x = LSTM(64, return_sequences=False, activation="tanh", recurrent_activation="sigmoid")(x)
x = Dropout(0.3)(x)
x = Dense(64, activation="relu")(x)   # match original, not 128
outputs = Dense(26, activation="softmax")(x)

cpu_model = keras.Model(inputs, outputs, name="ser_cpu_model")

# --- Transfer weights safely ---
for layer_cpu, layer_orig in zip(cpu_model.layers, original_model.layers):
    try:
        if layer_cpu.name.startswith("dense") and layer_cpu.output_shape[-1] != layer_orig.output_shape[-1]:
            print(f"âš ï¸ Skipping final Dense mismatch: {layer_cpu.name}")
            continue
        layer_cpu.set_weights(layer_orig.get_weights())
        print(f"âœ… Transferred weights for: {layer_cpu.name}")
    except Exception as e:
        print(f"âš ï¸ Skipped {layer_cpu.name}: {e}")

# --- Save as proper SavedModel (for TFLite) ---
cpu_model.export("ser_cpu_saved_model")
print("âœ… Exported CPU SER model ready for TFLite!")

import tensorflow as tf

# Convert
converter = tf.lite.TFLiteConverter.from_saved_model("ser_cpu_saved_model")
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS
]
tflite_model = converter.convert()

# Save to Drive
tflite_path = "/content/drive/MyDrive/Multimodal_Emotion_Models/SER_Model.tflite"
with open(tflite_path, "wb") as f:
    f.write(tflite_model)

print(f"ðŸŽ‰ SER model successfully converted to TFLite â†’ {tflite_path}")

new_model.export("ser_cpu_rnn_saved_model")

import tensorflow as tf

# Load SavedModel
converter = tf.lite.TFLiteConverter.from_saved_model("ser_cpu_rnn_saved_model")

# Allow both builtin TFLite ops and fallback to TensorFlow ops
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS
]

# Disable lowering of TensorList ops (needed for RNN/LSTM export)
converter._experimental_lower_tensor_list_ops = False

# (Optional) if you want smaller model -> quantize to float16
# converter.optimizations = [tf.lite.Optimize.DEFAULT]
# converter.target_spec.supported_types = [tf.float16]

# Convert
tflite_model = converter.convert()

# Save
with open("ser_cpu_rnn_model.tflite", "wb") as f:
    f.write(tflite_model)

print("âœ… TFLite model exported with Select TF Ops support!")

# Path in Drive
drive_path = "/content/drive/MyDrive/Multimodal_Emotion_Models/ser_cpu_rnn_model.tflite"

# Save to Drive
with open(drive_path, "wb") as f:
    f.write(tflite_model)

print(f"âœ… SER CPU RNN TFLite model saved to: {drive_path}")