# -*- coding: utf-8 -*-
"""Fusion_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SdvTJjbqgfyQzhyq5Bqfl8c9bzWiUtmc
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip -q "/content/drive/MyDrive/emotion-recognition-smartwatch-master (2).zip" -d "/content/emotion_recognition_HER"

# Change this path to where your ZIP is stored in Drive
zip_path = "/content/drive/MyDrive/emotion-recognition-using-speech-master.zip"

# Unzip into /content
!unzip -q "$zip_path" -d /content/

import os
import librosa
import numpy as np
import pandas as pd

DATA_PATH = "/content/emotion-recognition-using-speech-master/data/training"
FEATURES_CSV = "speech_features.csv"

features_list = []

for actor in os.listdir(DATA_PATH):
    actor_path = os.path.join(DATA_PATH, actor)
    if os.path.isdir(actor_path):
        for file in os.listdir(actor_path):
            if file.endswith(".wav"):
                file_path = os.path.join(actor_path, file)

                # Load audio
                y, sr = librosa.load(file_path, sr=None)

                # Extract MFCCs (mean of 40 coefficients)
                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
                mfccs_mean = np.mean(mfccs.T, axis=0)

                # Extract label safely
                label = file.split("_")[-1].replace(".wav", "")

                # Append features + label
                features_list.append(np.append(mfccs_mean, label))

# Convert to DataFrame and save
df = pd.DataFrame(features_list)
df.to_csv(FEATURES_CSV, index=False)
print(f"Saved {len(features_list)} feature rows to {FEATURES_CSV}")

pip install --upgrade tensorflow

import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Multiply, BatchNormalization, LeakyReLU, Add, GaussianNoise, LSTM, Bidirectional
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

# ===============================
# Load Data
# ===============================
speech_df = pd.read_csv("speech_features.csv")
X_speech = speech_df.iloc[:, :-1].values
y_speech = speech_df.iloc[:, -1].values
le = LabelEncoder()
y_encoded = le.fit_transform(y_speech)

her_path = "/content/emotion_recognition_HER/emotion-recognition-smartwatch-master/features"
her_files = [os.path.join(her_path, f) for f in os.listdir(her_path) if f.endswith(".csv")]
X_her = np.vstack([pd.read_csv(f).values for f in her_files])

# Match sample sizes
min_samples = min(X_speech.shape[0], X_her.shape[0])
X_speech = X_speech[:min_samples]
X_her = X_her[:min_samples]
y_encoded = y_encoded[:min_samples]

# Normalize
X_speech = StandardScaler().fit_transform(X_speech)
X_her = StandardScaler().fit_transform(X_her)

# Split
X_speech_train, X_speech_test, X_her_train, X_her_test, y_train, y_test = train_test_split(
    X_speech, X_her, y_encoded, test_size=0.2, random_state=42
)

# ===============================
# Speech Branch (MLP)
# ===============================
input_speech = Input(shape=(X_speech_train.shape[1],))
x1 = GaussianNoise(0.01)(input_speech)
x1_res = Dense(256)(x1)
x1_res = LeakyReLU(0.1)(x1_res)
x1_res = BatchNormalization()(x1_res)
x1 = Dense(256)(x1)
x1 = LeakyReLU(0.1)(x1)
x1 = BatchNormalization()(x1)
x1 = Dropout(0.15)(x1)
x1 = Add()([x1, x1_res])
x1 = Dense(128)(x1)
x1 = LeakyReLU(0.1)(x1)

# ===============================
# HER Branch (BiLSTM for temporal)
# ===============================
input_her = Input(shape=(X_her_train.shape[1], 1))
x2 = GaussianNoise(0.01)(input_her)
x2 = Bidirectional(LSTM(128, return_sequences=False))(x2)
x2 = Dense(128)(x2)
x2 = LeakyReLU(0.1)(x2)
x2 = BatchNormalization()(x2)
x2 = Dropout(0.15)(x2)

# ===============================
# Gated Fusion with Residual
# ===============================
gate_speech = Dense(128, activation='sigmoid')(x1)
gate_her = Dense(128, activation='sigmoid')(x2)
x1_weighted = Multiply()([x1, gate_speech])
x2_weighted = Multiply()([x2, gate_her])
concat = Concatenate()([x1_weighted, x2_weighted])
concat_res = Dense(256)(concat)
concat_res = LeakyReLU(0.1)(concat_res)
concat = Add()([concat, concat_res])

# ===============================
# Classification Layers
# ===============================
x = Dense(256)(concat)
x = LeakyReLU(0.1)(x)
x = BatchNormalization()(x)
x = Dropout(0.35)(x)
output = Dense(len(np.unique(y_encoded)), activation='softmax')(x)

# ===============================
# Model Compile
# ===============================
model = Model(inputs=[input_speech, input_her], outputs=output)
optimizer = Adam(learning_rate=1e-3)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ===============================
# Callbacks
# ===============================
early_stop = EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=1e-6, verbose=1)

# ===============================
# Reshape HER for LSTM (seq_len=features, 1)
# ===============================
X_her_train_seq = X_her_train[..., np.newaxis]
X_her_test_seq = X_her_test[..., np.newaxis]

# ===============================
# Train
# ===============================
history = model.fit(
    [X_speech_train, X_her_train_seq],
    y_train,
    validation_data=([X_speech_test, X_her_test_seq], y_test),
    epochs=400,
    batch_size=16,
    callbacks=[early_stop, reduce_lr],
    verbose=2
)

# ===============================
# Evaluate
# ===============================
loss, acc = model.evaluate([X_speech_test, X_her_test_seq], y_test)
print(f"Test Accuracy: {acc*100:.2f}%")

# Save as SavedModel (for TFLite)
model.export("multimodal_emotion_model")  # this creates a folder for SavedModel

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score
import numpy as np

# ===============================
# Predict on train and test sets
# ===============================
y_train_pred_prob = model.predict([X_speech_train, X_her_train])
y_test_pred_prob = model.predict([X_speech_test, X_her_test])

# Convert probabilities to class labels
y_train_pred = np.argmax(y_train_pred_prob, axis=1)
y_test_pred = np.argmax(y_test_pred_prob, axis=1)

# ===============================
# Accuracy and F1-Score
# ===============================
train_acc = accuracy_score(y_train, y_train_pred)
test_acc = accuracy_score(y_test, y_test_pred)
train_f1 = f1_score(y_train, y_train_pred, average='weighted')
test_f1 = f1_score(y_test, y_test_pred, average='weighted')

print(f"Train Accuracy: {train_acc*100:.2f}%")
print(f"Test Accuracy: {test_acc*100:.2f}%")
print(f"Train F1-score: {train_f1*100:.2f}%")
print(f"Test F1-score: {test_f1*100:.2f}%\n")

# ===============================
# Classification Report
# ===============================
print("Classification Report (Test Set):")
print(classification_report(y_test, y_test_pred, target_names=le.classes_))

# ===============================
# Confusion Matrix
# ===============================
cm = confusion_matrix(y_test, y_test_pred)

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ===============================
# Plot Training History
# ===============================
plt.figure(figsize=(12,5))

# Accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training & Validation Accuracy')
plt.legend()

# Loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training & Validation Loss')
plt.legend()

plt.show()

# ===============================
# Bar chart for F1-scores per class
# ===============================
report = classification_report(y_test, y_test_pred, target_names=le.classes_, output_dict=True)
f1_per_class = [report[cls]['f1-score'] for cls in le.classes_]

plt.figure(figsize=(8,5))
sns.barplot(x=le.classes_, y=f1_per_class, palette="viridis")
plt.ylabel('F1-score')
plt.title('F1-score per Class (Test Set)')
plt.ylim(0,1)
plt.show()

# Save entire model (architecture + weights + optimizer state)
model.save("/content/drive/MyDrive/Multimodal_Emotion_Models/Fusion_emotion.h5")
print("âœ… Model saved to Google Drive as Fusion_emotion.h5")

import tensorflow as tf

# Load your saved model
model = tf.keras.models.load_model("/content/drive/MyDrive/Multimodal_Emotion_Models/Fusion_emotion.h5")

# Create the TFLite converter
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# Optional: Enable optimization for smaller size & faster inference
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# Convert the model
tflite_model = converter.convert()

# Save the .tflite file
with open("Fusion_emotion_model.tflite", "wb") as f:
    f.write(tflite_model)

print("Conversion complete! Saved as Fusion_emotion_model.tflite")